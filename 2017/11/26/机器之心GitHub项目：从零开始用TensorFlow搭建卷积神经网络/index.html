<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="深度学习,tensorflow," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="本文的重点是实现，并不会从理论和概念上详细解释深度神经网络、卷积神经网络、最优化方法等基本内容。但是机器之心发过许多详细解释的入门文章或教程，因此，我们希望读者能先了解以下基本概念和理论。当然，本文注重实现，即使对深度学习的基本算法理解不那么深同样还是能实现本文所述的内容。">
<meta name="keywords" content="深度学习,tensorflow">
<meta property="og:type" content="article">
<meta property="og:title" content="机器之心GitHub项目：从零开始用TensorFlow搭建卷积神经网络【转】">
<meta property="og:url" content="http://yoursite.com/2017/11/26/机器之心GitHub项目：从零开始用TensorFlow搭建卷积神经网络/index.html">
<meta property="og:site_name" content="心雨达致">
<meta property="og:description" content="本文的重点是实现，并不会从理论和概念上详细解释深度神经网络、卷积神经网络、最优化方法等基本内容。但是机器之心发过许多详细解释的入门文章或教程，因此，我们希望读者能先了解以下基本概念和理论。当然，本文注重实现，即使对深度学习的基本算法理解不那么深同样还是能实现本文所述的内容。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://otue1rxl3.bkt.clouddn.com/17-11-27/98620237.jpg">
<meta property="og:image" content="http://otue1rxl3.bkt.clouddn.com/17-11-27/10952232.jpg">
<meta property="og:image" content="http://otue1rxl3.bkt.clouddn.com/17-11-27/91538923.jpg">
<meta property="og:updated_time" content="2017-11-27T14:13:27.798Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器之心GitHub项目：从零开始用TensorFlow搭建卷积神经网络【转】">
<meta name="twitter:description" content="本文的重点是实现，并不会从理论和概念上详细解释深度神经网络、卷积神经网络、最优化方法等基本内容。但是机器之心发过许多详细解释的入门文章或教程，因此，我们希望读者能先了解以下基本概念和理论。当然，本文注重实现，即使对深度学习的基本算法理解不那么深同样还是能实现本文所述的内容。">
<meta name="twitter:image" content="http://otue1rxl3.bkt.clouddn.com/17-11-27/98620237.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/11/26/机器之心GitHub项目：从零开始用TensorFlow搭建卷积神经网络/"/>





  <title>机器之心GitHub项目：从零开始用TensorFlow搭建卷积神经网络【转】 | 心雨达致</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?1e9e36dfff2baf430f723f50d54d376e";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">心雨达致</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/26/机器之心GitHub项目：从零开始用TensorFlow搭建卷积神经网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ailee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="心雨达致">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器之心GitHub项目：从零开始用TensorFlow搭建卷积神经网络【转】</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-11-26T21:55:04+08:00">
                2017-11-26
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2017-11-27T22:13:27+08:00">
                2017-11-27
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2017/11/26/机器之心GitHub项目：从零开始用TensorFlow搭建卷积神经网络/" class="leancloud_visitors" data-flag-title="机器之心GitHub项目：从零开始用TensorFlow搭建卷积神经网络【转】">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          
              <div class="post-description">
                  本文的重点是实现，并不会从理论和概念上详细解释深度神经网络、卷积神经网络、最优化方法等基本内容。但是机器之心发过许多详细解释的入门文章或教程，因此，我们希望读者能先了解以下基本概念和理论。当然，本文注重实现，即使对深度学习的基本算法理解不那么深同样还是能实现本文所述的内容。
              </div>
          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="1-1-张量和图"><a href="#1-1-张量和图" class="headerlink" title="1.1 张量和图"></a>1.1 张量和图</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 引入 tensorflow</span></div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 定义两个变量</span></div><div class="line">a = tf.constant(<span class="number">2</span>, tf.int16)</div><div class="line">b = tf.constant(<span class="number">4</span>, tf.float32)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 定义一张图</span></div><div class="line">graph = tf.Graph()</div><div class="line"><span class="keyword">with</span> graph.as_default():</div><div class="line">    <span class="comment"># 定义两个变量</span></div><div class="line">    a = tf.Variable(<span class="number">8</span>, tf.float32)</div><div class="line">    b = tf.Variable(tf.zeros([<span class="number">2</span>,<span class="number">2</span>]), tf.float32)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># </span></div><div class="line"><span class="keyword">with</span> tf.Session(graph=graph) <span class="keyword">as</span> session:</div><div class="line">    tf.global_variables_initializer().run()</div><div class="line">    <span class="comment"># print(f)</span></div><div class="line">    print(session.run(a))</div><div class="line">    print(session.run(b))</div></pre></td></tr></table></figure>
<pre><code>8
[[ 0.  0.]
 [ 0.  0.]]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 声明一个 2 行 3 列的变量矩阵，该变量的值服从标准差为 1 的正态分布，并随机生成</span></div><div class="line">w1 = tf.Variable(tf.random_normal([<span class="number">2</span>,<span class="number">3</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 应用变量来定义神经网络中的权重矩阵和偏置项向量：</span></div><div class="line"><span class="comment"># truncated_normal()</span></div><div class="line"><span class="comment"># Outputs random values from a truncated normal distribution（截断正态分布）.</span></div><div class="line">weights = tf.Variable(tf.truncated_normal([<span class="number">256</span> * <span class="number">256</span>, <span class="number">10</span>]))</div><div class="line">biases = tf.Variable(tf.zeros([<span class="number">10</span>]))</div><div class="line">print(weights.get_shape().as_list())</div><div class="line">print(biases.get_shape().as_list())</div></pre></td></tr></table></figure>
<pre><code>[65536, 10]
[10]
</code></pre><h1 id="1-2-占位符和feed-dict"><a href="#1-2-占位符和feed-dict" class="headerlink" title="1.2 占位符和feed_dict"></a>1.2 占位符和feed_dict</h1><p>占位符并没有初始值，它只会分配必要的内存。在会话中，占位符可以使用 feed_dict 馈送数据。</p>
<p>feed_dict 是一个字典，在字典中需要给出每一个用到的占位符的取值。在训练神经网络时需要每次提供一个批量的训练样本，如果每次迭代选取的数据要通过常量表示，那么 TensorFlow 的计算图会非常大。因为每增加一个常量，TensorFlow 都会在计算图中增加一个结点。所以说拥有几百万次迭代的神经网络会拥有极其庞大的计算图，而占位符却可以解决这一点，它只会拥有占位符这一个结点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">w1 = tf.Variable(tf.random_normal([<span class="number">1</span>, <span class="number">2</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</div><div class="line"><span class="comment"># 因为需要重复输入x，而每建一个x就会生成一个结点，计算图的效率会低。所以使用占位符</span></div><div class="line">x = tf.placeholder(tf.float32, shape=(<span class="number">1</span>,<span class="number">2</span>))</div><div class="line">x1 = tf.constant([<span class="number">0.7</span>, <span class="number">0.9</span>])</div><div class="line"></div><div class="line">a = x + w1</div><div class="line">b = x1 + w1</div><div class="line"></div><div class="line">sees = tf.Session()</div><div class="line">sees.run(tf.global_variables_initializer())</div><div class="line"></div><div class="line"><span class="comment"># 运行y时将占位符填上，feed_dict为字典，变量名不可变</span></div><div class="line">y_1 = sees.run(a, feed_dict=&#123;x:[[<span class="number">0.7</span>, <span class="number">0.9</span>]]&#125;)</div><div class="line">y_2 = sees.run(b)</div><div class="line">print(<span class="string">"使用占位符计算"</span>)</div><div class="line">print(y_1)</div><div class="line">print(<span class="string">"常亮计算"</span>)</div><div class="line">print(y_2)</div><div class="line">sees.close</div></pre></td></tr></table></figure>
<pre><code>使用占位符计算
[[-0.11131823  2.38459873]]
常亮计算
[[-0.11131823  2.38459873]]





&lt;bound method BaseSession.close of &lt;tensorflow.python.client.session.Session object at 0x000000000CB44780&gt;&gt;
</code></pre><h2 id="下面是使用占位符的案例："><a href="#下面是使用占位符的案例：" class="headerlink" title="下面是使用占位符的案例："></a>下面是使用占位符的案例：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 计算两点间的欧氏距离</span></div><div class="line">list_of_points1_ = [[<span class="number">1</span>,<span class="number">2</span>], [<span class="number">3</span>,<span class="number">4</span>], [<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">8</span>]]</div><div class="line">list_of_points2_ = [[<span class="number">15</span>,<span class="number">16</span>], [<span class="number">13</span>, <span class="number">14</span>], [<span class="number">11</span>,<span class="number">12</span>], [<span class="number">9</span>, <span class="number">10</span>]]</div><div class="line"></div><div class="line">list_of_points1 = np.array([np.array(elem).reshape(<span class="number">1</span>,<span class="number">2</span>) <span class="keyword">for</span> elem <span class="keyword">in</span> list_of_points1_])</div><div class="line">list_of_points2 = np.array([np.array(elem).reshape(<span class="number">1</span>,<span class="number">2</span>) <span class="keyword">for</span> elem <span class="keyword">in</span> list_of_points2_])</div><div class="line"></div><div class="line"><span class="comment"># 新建一张图</span></div><div class="line">graph = tf.Graph()</div><div class="line"></div><div class="line"><span class="keyword">with</span> graph.as_default():</div><div class="line">    <span class="comment"># 我们使用 tf.placeholder() 创建占位符 ，在 session.run() 过程中再投递数据 </span></div><div class="line">    point1 = tf.placeholder(tf.float32, shape=(<span class="number">1</span>,<span class="number">2</span>))</div><div class="line">    point2 = tf.placeholder(tf.float32, shape=(<span class="number">1</span>,<span class="number">2</span>))</div><div class="line">    </div><div class="line">    <span class="comment"># 定义一个函数</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calculate_eucledian_distance</span><span class="params">(point1, point2)</span>:</span></div><div class="line">        difference = tf.subtract(point1, point2)</div><div class="line">        power2 = tf.pow(difference, tf.constant(<span class="number">2.0</span>, shape=(<span class="number">1</span>,<span class="number">2</span>)))</div><div class="line">        <span class="comment"># 计算一个张量维数的总和</span></div><div class="line">        add = tf.reduce_sum(power2)</div><div class="line">        eucledian_distance = tf.sqrt(add)</div><div class="line">        <span class="keyword">return</span> eucledian_distance</div><div class="line">    </div><div class="line">    dist = calculate_eucledian_distance(point1, point2)</div><div class="line">    </div><div class="line"><span class="keyword">with</span> tf.Session(graph=graph) <span class="keyword">as</span> session:</div><div class="line">    tf.global_variables_initializer().run()</div><div class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> range(len(list_of_points1)):</div><div class="line">        point1_ = list_of_points1[ii]</div><div class="line">        point2_ = list_of_points2[ii]</div><div class="line">        </div><div class="line">        <span class="comment"># 使用feed_dict将数据投入到[dist]中</span></div><div class="line">        feed_dict = &#123;point1: point1_, point2: point2_&#125;</div><div class="line">        distance = session.run([dist], feed_dict=feed_dict)</div><div class="line">        print(<span class="string">"the distance between &#123;&#125; and &#123;&#125; -&gt; &#123;&#125;"</span>.format(point1_, point2_, distance))</div></pre></td></tr></table></figure>
<pre><code>the distance between [[1 2]] and [[15 16]] -&gt; [19.79899]
the distance between [[3 4]] and [[13 14]] -&gt; [14.142136]
the distance between [[5 6]] and [[11 12]] -&gt; [8.485281]
the distance between [[7 8]] and [[ 9 10]] -&gt; [2.8284271]
</code></pre><h2 id="解析一段构建了三层全连接神经网络的代码"><a href="#解析一段构建了三层全连接神经网络的代码" class="headerlink" title="解析一段构建了三层全连接神经网络的代码"></a>解析一段构建了三层全连接神经网络的代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> RandomState</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 每次迭代读取的批量为 10</span></div><div class="line">batch_size = <span class="number">10</span></div><div class="line">w1 = tf.Variable(tf.random_normal([<span class="number">2</span>,<span class="number">3</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</div><div class="line">w2 = tf.Variable(tf.random_normal([<span class="number">3</span>,<span class="number">1</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># None 可以根据batch 大小确定纬度，在shape 的一个纬度上使用None</span></div><div class="line">x = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, <span class="number">2</span>))</div><div class="line">y = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, <span class="number">1</span>))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 激活函数使用ReLU</span></div><div class="line"><span class="comment"># tf.nn.relu() 代表调用 ReLU 激活函数</span></div><div class="line"><span class="comment"># tf.matmul() 为矩阵乘法</span></div><div class="line">a = tf.nn.relu(tf.matmul(x,w1))</div><div class="line">yhat = tf.nn.relu(tf.matmul(a,w2))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 定义交叉熵为损失函数，训练过程使用Adam算法最小化交叉熵</span></div><div class="line"><span class="comment"># tf.clip_by_value(yhat,1e-10,1.0) 这一语句代表的是截断 yhat 的值</span></div><div class="line">cross_entropy = tf.reduce_mean(y * tf.log(tf.clip_by_value(yhat, <span class="number">1e-10</span>, <span class="number">1.0</span>)))</div><div class="line"><span class="comment"># tf.train.AdamOptimizer(learning_rate).minimize(cost_function) 是进行训练的函数，其中我们采用的是 Adam 优化算法更新权重，并且需要提供学习速率和损失函数这两个参数。</span></div><div class="line">train_step = tf.train.AdamOptimizer(<span class="number">0.001</span>).minimize(cross_entropy)</div><div class="line"></div><div class="line">rdm = RandomState(<span class="number">1</span>)</div><div class="line">data_size = <span class="number">512</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 生成两个特征，共data_size个样本</span></div><div class="line">X = rdm.rand(data_size, <span class="number">2</span>)</div><div class="line"><span class="comment"># 定义规则给出样本标签，所用x1+x2&lt;1的样本为正样本，其他为负样本，Y,1为正样本</span></div><div class="line">Y = [[int(x1+x2 &lt; <span class="number">1</span>)] <span class="keyword">for</span> (x1, x2) <span class="keyword">in</span> X]</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 创建一个会话</span></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(tf.global_variables_initializer())</div><div class="line">    print(sess.run(w1))</div><div class="line">    print(sess.run(w2))</div><div class="line">    steps = <span class="number">11000</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(steps):</div><div class="line">        <span class="comment"># 选取每一个批量读取的首位位置，确保在1个epoch内采样训练</span></div><div class="line">        start = i * batch_size % data_size</div><div class="line">        end = min(start + batch_size, data_size)</div><div class="line">        sess.run(train_step, feed_dict=&#123;x:X[start:end], y:Y[start:end]&#125;)</div><div class="line">        <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</div><div class="line">            training_loss = sess.run(cross_entropy, feed_dict=&#123;x:X, y:Y&#125;)</div><div class="line">            print(<span class="string">"在迭代 %d 次后，训练损失为 %g"</span>%(i, training_loss))</div></pre></td></tr></table></figure>
<pre><code>[[-0.81131822  1.48459876  0.06532937]
 [-2.4427042   0.0992484   0.59122431]]
[[-0.81131822]
 [ 1.48459876]
 [ 0.06532937]]
在迭代 0 次后，训练损失为 -0.311019
在迭代 1000 次后，训练损失为 -11.1082
在迭代 2000 次后，训练损失为 -11.1082
在迭代 3000 次后，训练损失为 -11.1082
在迭代 4000 次后，训练损失为 -11.1082
在迭代 5000 次后，训练损失为 -11.1082
在迭代 6000 次后，训练损失为 -11.1082
在迭代 7000 次后，训练损失为 -11.1082
在迭代 8000 次后，训练损失为 -11.1082
在迭代 9000 次后，训练损失为 -11.1082
在迭代 10000 次后，训练损失为 -11.1082
</code></pre><p>上面的代码定义了一个简单的三层全连接网络（输入层、隐藏层和输出层分别为 2、3 和 1 个神经元），隐藏层和输出层的激活函数使用的是 ReLU 函数。该模型训练的样本总数为 512，每次迭代读取的批量为 10。这个简单的全连接网络以交叉熵为损失函数，并使用 Adam 优化算法进行权重更新。</p>
<h1 id="tensorflow中的神经网络"><a href="#tensorflow中的神经网络" class="headerlink" title="tensorflow中的神经网络"></a>tensorflow中的神经网络</h1><h2 id="2-1-简介"><a href="#2-1-简介" class="headerlink" title="2.1 简介"></a>2.1 简介</h2><p><img src="http://otue1rxl3.bkt.clouddn.com/17-11-27/98620237.jpg" alt=""></p>
<ul>
<li>1 定义一些函数，便于对数据进行预处理</li>
</ul>
<h2 id="2-2-导入数据集"><a href="#2-2-导入数据集" class="headerlink" title="2.2 导入数据集"></a>2.2 导入数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomize</span><span class="params">(dataset, labels)</span>:</span></div><div class="line">    permutation = np.random.permutation(labels.shape[<span class="number">0</span>])</div><div class="line">    shuffed_dataset = dataset[permutation, :, :]</div><div class="line">    shuffed_labels = labels[permutation]</div><div class="line">    <span class="keyword">return</span> shuffed_dataset, shuffed_labels</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">one_hot_encode</span><span class="params">(np_array)</span>:</span></div><div class="line">    <span class="keyword">return</span> (np.arange(<span class="number">10</span>) == np_array[:, <span class="keyword">None</span>]).astype(np.float32)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">reformat_data</span><span class="params">(dataset, labels, image_width, image_height, image_depth)</span>:</span></div><div class="line">    np_dataset_ = np.array([np.array(image_data).reshape(image_width, image_height, image_depth) <span class="keyword">for</span> image_data <span class="keyword">in</span> dataset])</div><div class="line">    np_labels_ = one_hot_encode(np.array(labels,dtype=np.float32))</div><div class="line">    np_dataset, np_labels = randomize(np_dataset_, np_labels_)</div><div class="line">    <span class="keyword">return</span> np_dataset, np_labels</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatten_tf_array</span><span class="params">(array)</span>:</span></div><div class="line">    shape = array.get_shape.as_list()</div><div class="line">    <span class="keyword">return</span> tf.reshape(array, [shape[<span class="number">0</span>], shape[<span class="number">1</span>] * shape[<span class="number">2</span>] * shape[<span class="number">3</span>]])</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span><span class="params">(predictions, labels)</span>:</span></div><div class="line">    <span class="keyword">return</span> (<span class="number">100.0</span> * np.sum(np.argmax(predictions, <span class="number">1</span>) == np.argmax(labels, <span class="number">1</span>)) / predictions.shape[<span class="number">0</span>])</div></pre></td></tr></table></figure>
<ul>
<li>导入数据集</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">%pwd</div></pre></td></tr></table></figure>
<pre><code>&apos;E:\\jupyter notebook&apos;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">################################### 导入 mnist 数据集 ################################</span></div><div class="line"><span class="keyword">from</span> mnist <span class="keyword">import</span> MNIST</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">mnist_folder = <span class="string">'.\data\mnist'</span></div><div class="line">mnist_image_width = <span class="number">28</span></div><div class="line">mnist_image_height = <span class="number">28</span></div><div class="line">mnist_image_depth = <span class="number">1</span></div><div class="line">mnist_num_labels = <span class="number">10</span></div><div class="line">mndata = MNIST(mnist_folder)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 导入训练集和测试集</span></div><div class="line">mnist_train_dataset_, mnist_train_labels_ = mndata.load_training()</div><div class="line">mnist_test_dataset_, mnist_test_labels_ = mndata.load_testing()</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 重新改变数据集的形状</span></div><div class="line">mnist_train_dataset, mnist_train_labels = reformat_data(mnist_train_dataset_, mnist_train_labels_, mnist_image_width, mnist_image_height, mnist_image_depth)</div><div class="line">mnist_test_dataset, mnist_test_labels = reformat_data(mnist_test_dataset_, mnist_test_labels_, mnist_image_width, mnist_image_height, mnist_image_depth)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 打印所导入数据集的相关信息</span></div><div class="line">print(<span class="string">"There are &#123;&#125; images, each of size &#123;&#125;."</span>.format(len(mnist_train_dataset), len(mnist_train_dataset[<span class="number">0</span>])))</div><div class="line">print(<span class="string">"Meaning each image has the size of 28*28*1 = &#123;&#125;."</span>.format(mnist_image_width * mnist_image_height * <span class="number">1</span>))</div><div class="line">print(<span class="string">"The training set contains the following &#123;&#125; labels: &#123;&#125;."</span>.format(len(np.unique(mnist_train_labels_)), np.unique(mnist_train_labels_)))</div><div class="line"></div><div class="line">print(<span class="string">"Training set shape "</span>, mnist_train_dataset.shape, mnist_train_labels.shape)</div><div class="line">print(<span class="string">"Test set shape "</span>, mnist_test_dataset.shape, mnist_test_labels.shape)</div></pre></td></tr></table></figure>
<pre><code>There are 60000 images, each of size 28.
Meaning each image has the size of 28*28*1 = 784.
The training set contains the following 10 labels: [0 1 2 3 4 5 6 7 8 9].
Training set shape  (60000, 28, 28, 1) (60000, 10)
Test set shape  (10000, 28, 28, 1) (10000, 10)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 显示图像</span></div><div class="line">im = mnist_train_dataset[<span class="number">0</span>].reshape([<span class="number">28</span>,<span class="number">28</span>])</div><div class="line">image = Image.fromarray(im)</div><div class="line">plt.imshow(image)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="http://otue1rxl3.bkt.clouddn.com/17-11-27/10952232.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">train_dataset_mnist, train_labels_mnist = mnist_train_dataset, mnist_train_labels</div><div class="line">test_dataset_mnist, test_labels_mnist = mnist_test_dataset, mnist_test_labels</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">################################## 导入 CIFAR-10 数据集 ###############################</span></div><div class="line"><span class="keyword">import</span> pickle</div><div class="line"></div><div class="line">cifar10_folder = <span class="string">'.\\data\\cifar10\\'</span></div><div class="line">train_datasets = [<span class="string">'data_batch_1'</span>, <span class="string">'data_batch_2'</span>, <span class="string">'data_batch_3'</span>, <span class="string">'data_batch_4'</span>, <span class="string">'data_batch_5'</span>,]</div><div class="line">test_dataset = [<span class="string">'test_batch'</span>]</div><div class="line">c10_image_height = <span class="number">32</span></div><div class="line">c10_image_width = <span class="number">32</span></div><div class="line">c10_image_depth = <span class="number">3</span></div><div class="line">c10_num_labels = <span class="number">10</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 导入测试集</span></div><div class="line"><span class="keyword">with</span> open(cifar10_folder + test_dataset[<span class="number">0</span>], <span class="string">'rb'</span>) <span class="keyword">as</span> f0:</div><div class="line">    c10_test_dict = pickle.load(f0, encoding=<span class="string">'bytes'</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">c10_test_dataset, c10_test_labels = c10_test_dict[<span class="string">b'data'</span>], c10_test_dict[<span class="string">b'labels'</span>]</div><div class="line">test_dataset_cifar10, test_labels_cifar10 = reformat_data(c10_test_dataset, c10_test_labels, c10_image_width, c10_image_height, c10_image_depth)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 导入训练集</span></div><div class="line">c10_train_dataset, c10_train_labels = [], []</div><div class="line"><span class="keyword">for</span> train_dataset <span class="keyword">in</span> train_datasets:</div><div class="line">    <span class="keyword">with</span> open(cifar10_folder + train_dataset, <span class="string">'rb'</span>) <span class="keyword">as</span> f0:</div><div class="line">        c10_train_dict = pickle.load(f0, encoding=<span class="string">'bytes'</span>)</div><div class="line">        c10_train_dataset_, c10_train_labels_ = c10_train_dict[<span class="string">b'data'</span>], c10_train_dict[<span class="string">b'labels'</span>]</div><div class="line">        </div><div class="line">        c10_train_dataset.append(c10_train_dataset_)</div><div class="line">        c10_train_labels += c10_train_labels_</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">c10_train_dataset = np.concatenate(c10_train_dataset, axis=<span class="number">0</span>)</div><div class="line">train_dataset_cifar10, train_labels_cifar10 = reformat_data(c10_train_dataset, c10_train_labels, c10_image_width, c10_image_height, c10_image_depth)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 打印所导入数据集的相关信息</span></div><div class="line">print(<span class="string">"The training set contains the following labels: &#123;&#125;"</span>.format(np.unique(c10_train_dict[<span class="string">b'labels'</span>])))</div><div class="line">print(<span class="string">"Training set shape "</span>, train_dataset_cifar10.shape, train_labels_cifar10.shape)</div><div class="line">print(<span class="string">"Test set shape "</span>, test_dataset_cifar10.shape, test_labels_cifar10.shape)</div></pre></td></tr></table></figure>
<pre><code>The training set contains the following labels: [0 1 2 3 4 5 6 7 8 9]
Training set shape  (50000, 32, 32, 3) (50000, 10)
Test set shape  (10000, 32, 32, 3) (10000, 10)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">c10_im = train_dataset_cifar10[<span class="number">0</span>]</div><div class="line">c10_image_r = Image.fromarray(c10_im[:, :, <span class="number">0</span>]).convert(<span class="string">'L'</span>)</div><div class="line">c10_image_g = Image.fromarray(c10_im[:, :, <span class="number">1</span>]).convert(<span class="string">'L'</span>)</div><div class="line">c10_image_b = Image.fromarray(c10_im[:, :, <span class="number">2</span>]).convert(<span class="string">'L'</span>)</div><div class="line">c10_image = Image.merge(<span class="string">"RGB"</span>, (c10_image_r, c10_image_g, c10_image_b))</div><div class="line">plt.imshow(c10_image)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="http://otue1rxl3.bkt.clouddn.com/17-11-27/91538923.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">c10_im[:,:,<span class="number">0</span>]</div></pre></td></tr></table></figure>
<pre><code>array([[196, 203, 217, ..., 148, 120,  86],
       [113, 113, 126, ...,  99, 146, 144],
       [127, 116, 159, ..., 190, 203, 174],
       ..., 
       [158, 112,  81, ..., 113,  79,  39],
       [143, 131,  67, ...,  44,  38,  51],
       [123, 125, 111, ...,  53,  79, 120]], dtype=uint8)
</code></pre><h2 id="2-3-搭建一个简单的神经网络"><a href="#2-3-搭建一个简单的神经网络" class="headerlink" title="2.3 搭建一个简单的神经网络"></a>2.3 搭建一个简单的神经网络</h2><p>最简单的神经网络为一层线性全连接神经网络，数学上它由矩阵乘法组成。</p>
<p>在学习TensorFlow的过程中，最好先从这样最简单的神经网络开始，然后再接触更加复杂的神经网络。当我们开始研究更复杂的神经网络时，只有图的模型（步骤二）和权重（步骤三）将会发生改变，而其他部分都保持不变。</p>
<p>下面开始构建一个类似的简单神经网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">image_width = mnist_image_width</div><div class="line">image_height = mnist_image_height</div><div class="line">image_depth = mnist_image_depth</div><div class="line">num_labels = mnist_num_labels</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 数据集</span></div><div class="line">train_dataset = mnist_train_dataset</div><div class="line">train_labels = mnist_train_labels</div><div class="line">test_dataset = mnist_test_dataset</div><div class="line">test_labels = mnist_test_labels</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 迭代次数和学习速率</span></div><div class="line">num_steps = <span class="number">10001</span></div><div class="line">display_step = <span class="number">1000</span></div><div class="line">batch_size = <span class="number">1</span></div><div class="line">learning_rate = <span class="number">0.5</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_width, image_height, image_depth))</div><div class="line"><span class="comment"># shape = array.get_shape.as_list()</span></div><div class="line">shape = tf_train_dataset.shape.as_list()</div><div class="line">print(shape)</div><div class="line">tf_train_dataset_reshape = tf.reshape(tf_train_dataset, [shape[<span class="number">0</span>], shape[<span class="number">1</span>] * shape[<span class="number">2</span>] * shape[<span class="number">3</span>]])</div><div class="line">print(tf_train_dataset_reshape.shape)</div></pre></td></tr></table></figure>
<pre><code>[1, 28, 28, 1]
(1, 784)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 构建TensorFlow图</span></div><div class="line">graph = tf.Graph()</div><div class="line"><span class="keyword">with</span> graph.as_default():</div><div class="line">    <span class="comment"># 1) 首先将数据按照TensorFlow友好的格式输入</span></div><div class="line">    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_width, image_height, image_depth))</div><div class="line">    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))</div><div class="line">    tf_test_dataset = tf.constant(test_dataset, tf.float32)</div><div class="line">    </div><div class="line">    <span class="comment"># 2) 初始化权重矩阵和偏差向量</span></div><div class="line">    <span class="comment"># 默认使用tf.truncated_normal() 产生权重矩阵，</span></div><div class="line">    <span class="comment"># 默认使用tf.zeros() 产生偏差向量</span></div><div class="line">    weights = tf.Variable(tf.truncated_normal([image_width * image_height * image_depth, num_labels]), tf.float32)</div><div class="line">    bias = tf.Variable(tf.zeros([num_labels]), tf.float32)</div><div class="line">    </div><div class="line">    <span class="comment"># 3) 定义模型</span></div><div class="line">    <span class="comment"># 由矩阵乘法构成的一层全连接神经网络</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(data, weights, bias)</span>:</span></div><div class="line">        shape = data.shape.as_list()</div><div class="line">        data = tf.reshape(data, [shape[<span class="number">0</span>], shape[<span class="number">1</span>] * shape[<span class="number">2</span>] * shape[<span class="number">3</span>]])</div><div class="line">        <span class="keyword">return</span> tf.matmul(data, weights) + bias</div><div class="line">    </div><div class="line">    logits = model(tf_train_dataset, weights, bias)</div><div class="line">    </div><div class="line">    <span class="comment"># 4) 计算loss</span></div><div class="line">    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))</div><div class="line">    </div><div class="line">    <span class="comment"># 5) 选择优化器，进行优化</span></div><div class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)</div><div class="line">    </div><div class="line">    <span class="comment"># 6) 训练数据集和测试数据集中图像的预测值分配给变量train_prediction和test_prediction。</span></div><div class="line">    <span class="comment"># It is only necessary if you want to know the accuracy by comparing it with the actual values.</span></div><div class="line">    train_prediction = tf.nn.softmax(logits)</div><div class="line">    test_prediction = tf.nn.softmax(model(tf_test_dataset, weights, bias))</div><div class="line">    </div><div class="line"><span class="keyword">with</span> tf.Session(graph=graph) <span class="keyword">as</span> session:</div><div class="line">    tf.global_variables_initializer().run()</div><div class="line">    print(<span class="string">"初始化完成！！！"</span>)</div><div class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(num_steps):</div><div class="line">        </div><div class="line">        start = step * batch_size % <span class="number">60000</span></div><div class="line">        end = min(start + batch_size, <span class="number">60000</span>)</div><div class="line">        </div><div class="line">        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=&#123;tf_train_dataset:train_dataset[start:end], tf_train_labels:train_labels[start:end]&#125;)</div><div class="line">        <span class="keyword">if</span>(step % display_step == <span class="number">0</span>):</div><div class="line">            train_accuracy = accuracy(predictions, train_labels[:, :])</div><div class="line">            <span class="comment"># test_accuracy = accuracy(test_prediction, test_labels)</span></div><div class="line">            message = <span class="string">"step &#123;:04d&#125; : loss is &#123;:06.2f&#125;, accuracy on training set &#123;:02.2f&#125; %"</span>.format(step, l, train_accuracy)</div><div class="line">            print(message)</div></pre></td></tr></table></figure>
<pre><code>初始化完成！！！
step 0000 : loss is 000.00, accuracy on training set 626500.00 %
step 1000 : loss is 000.00, accuracy on training set 626500.00 %
step 2000 : loss is 000.00, accuracy on training set 674200.00 %
step 3000 : loss is 000.00, accuracy on training set 585100.00 %
step 4000 : loss is 5932370.50, accuracy on training set 542100.00 %
step 5000 : loss is 2306888.00, accuracy on training set 542100.00 %
step 6000 : loss is 000.00, accuracy on training set 626500.00 %
step 7000 : loss is 000.00, accuracy on training set 595800.00 %
step 8000 : loss is 000.00, accuracy on training set 594900.00 %
step 9000 : loss is 000.00, accuracy on training set 592300.00 %
step 10000 : loss is 000.00, accuracy on training set 585100.00 %
</code></pre><ul>
<li>上面是原作者的代码，好像有什么问题，目前还太菜了，等懂得多了再来看看；</li>
<li>下面的代码源于机器之心，亲测好使；</li>
<li>下面我们实现的神经网络共有三层，输入层有 784 个神经元，隐藏层与输出层分别有 500 和 10 个神经元。这所以这样设计是因为 MNIST 的像素为28×28=784，所以每一个输入神经元对应于一个灰度像素点。机器之心执行该模型得到的效果非常好，该模型在批量大小为 100，并使用学习率衰减的情况下迭代 10000 步能得到 98.34% 的测试集准确度，以下是该模型代码：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="comment"># from tensorflow.examples.tutorials.mnist import input_data</span></div><div class="line"></div><div class="line"><span class="comment">#加载MNIST数据集</span></div><div class="line">mnist = input_data.read_data_sets(<span class="string">"./data/mnist/"</span>, one_hot=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<pre><code>Extracting ./data/mnist/train-images-idx3-ubyte.gz
Extracting ./data/mnist/train-labels-idx1-ubyte.gz
Extracting ./data/mnist/t10k-images-idx3-ubyte.gz
Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div></pre></td><td class="code"><pre><div class="line">INPUT_NODE = <span class="number">784</span>     </div><div class="line">OUTPUT_NODE = <span class="number">10</span>     </div><div class="line">LAYER1_NODE = <span class="number">500</span>         </div><div class="line">BATCH_SIZE = <span class="number">100</span>       </div><div class="line"></div><div class="line"><span class="comment"># 模型相关的参数</span></div><div class="line">LEARNING_RATE_BASE = <span class="number">0.8</span>      </div><div class="line">LEARNING_RATE_DECAY = <span class="number">0.99</span>    </div><div class="line">REGULARAZTION_RATE = <span class="number">0.0001</span>   </div><div class="line">TRAINING_STEPS = <span class="number">10000</span>        </div><div class="line">MOVING_AVERAGE_DECAY = <span class="number">0.99</span> </div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span><span class="params">(input_tensor, avg_class, weights1, biases1, weights2, biases2)</span>:</span></div><div class="line">    <span class="comment"># 使用滑动平均类</span></div><div class="line">    <span class="keyword">if</span> avg_class == <span class="keyword">None</span>:</div><div class="line">        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)</div><div class="line">        <span class="keyword">return</span> tf.matmul(layer1, weights2) + biases2</div><div class="line"></div><div class="line">    <span class="keyword">else</span>:</div><div class="line"></div><div class="line">        layer1 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(weights1)) + avg_class.average(biases1))</div><div class="line">        <span class="keyword">return</span> tf.matmul(layer1, avg_class.average(weights2)) + avg_class.average(biases2)  </div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(mnist)</span>:</span></div><div class="line">    x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, INPUT_NODE], name=<span class="string">'x-input'</span>)</div><div class="line">    y_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, OUTPUT_NODE], name=<span class="string">'y-input'</span>)</div><div class="line"></div><div class="line">    <span class="comment"># 生成隐藏层的参数。</span></div><div class="line">    weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=<span class="number">0.1</span>))</div><div class="line">    biases1 = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[LAYER1_NODE]))</div><div class="line"></div><div class="line">    <span class="comment"># 生成输出层的参数。</span></div><div class="line">    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=<span class="number">0.1</span>))</div><div class="line">    biases2 = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[OUTPUT_NODE]))</div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment"># 计算不含滑动平均类的前向传播结果</span></div><div class="line">    y = inference(x, <span class="keyword">None</span>, weights1, biases1, weights2, biases2)</div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment"># 定义训练轮数及相关的滑动平均类 </span></div><div class="line">    global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="keyword">False</span>)</div><div class="line">    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)</div><div class="line">    variables_averages_op = variable_averages.apply(tf.trainable_variables())</div><div class="line">    average_y = inference(x, variable_averages, weights1, biases1, weights2, biases2)</div><div class="line"></div><div class="line">    <span class="comment"># 计算交叉熵及其平均值</span></div><div class="line">    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, <span class="number">1</span>))</div><div class="line">    cross_entropy_mean = tf.reduce_mean(cross_entropy)</div><div class="line"></div><div class="line">    <span class="comment"># 定义交叉熵损失函数加上正则项为模型损失函数</span></div><div class="line">    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)</div><div class="line">    regularaztion = regularizer(weights1) + regularizer(weights2)</div><div class="line">    loss = cross_entropy_mean + regularaztion</div><div class="line"></div><div class="line">    <span class="comment"># 设置指数衰减的学习率。</span></div><div class="line">    learning_rate = tf.train.exponential_decay(</div><div class="line">        LEARNING_RATE_BASE,</div><div class="line">        global_step,</div><div class="line">        mnist.train.num_examples / BATCH_SIZE,</div><div class="line">        LEARNING_RATE_DECAY,</div><div class="line">        staircase=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">    <span class="comment"># 随机梯度下降优化器优化损失函数</span></div><div class="line">    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)</div><div class="line"></div><div class="line">    <span class="comment"># 反向传播更新参数和更新每一个参数的滑动平均值</span></div><div class="line">    <span class="keyword">with</span> tf.control_dependencies([train_step, variables_averages_op]):</div><div class="line">        train_op = tf.no_op(name=<span class="string">'train'</span>)</div><div class="line"></div><div class="line">    <span class="comment"># 计算准确度</span></div><div class="line">    correct_prediction = tf.equal(tf.argmax(average_y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</div><div class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div><div class="line"></div><div class="line">    <span class="comment"># 初始化会话并开始训练过程。</span></div><div class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">        tf.global_variables_initializer().run()</div><div class="line">        validate_feed = &#123;x: mnist.validation.images, y_: mnist.validation.labels&#125;</div><div class="line">        test_feed = &#123;x: mnist.test.images, y_: mnist.test.labels&#125; </div><div class="line"></div><div class="line">        <span class="comment"># 循环地训练神经网络。</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(TRAINING_STEPS):</div><div class="line">            <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</div><div class="line">                validate_acc = sess.run(accuracy, feed_dict=validate_feed)</div><div class="line">                print(<span class="string">"After %d training step(s), validation accuracy using average model is %g "</span> % (i, validate_acc))</div><div class="line"></div><div class="line">            xs,ys=mnist.train.next_batch(BATCH_SIZE)</div><div class="line">            sess.run(train_op,feed_dict=&#123;x:xs,y_:ys&#125;)</div><div class="line"></div><div class="line">        test_acc=sess.run(accuracy,feed_dict=test_feed)</div><div class="line">        print((<span class="string">"After %d training step(s), test accuracy using average model is %g"</span> %(TRAINING_STEPS, test_acc)))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train(mnist)</div></pre></td></tr></table></figure>
<pre><code>After 0 training step(s), validation accuracy using average model is 0.1188 
After 1000 training step(s), validation accuracy using average model is 0.978 
After 2000 training step(s), validation accuracy using average model is 0.9814 
After 3000 training step(s), validation accuracy using average model is 0.9848 
After 4000 training step(s), validation accuracy using average model is 0.9852 
After 5000 training step(s), validation accuracy using average model is 0.985 
After 6000 training step(s), validation accuracy using average model is 0.9856 
After 7000 training step(s), validation accuracy using average model is 0.9848 
After 8000 training step(s), validation accuracy using average model is 0.986 
After 9000 training step(s), validation accuracy using average model is 0.986 
After 10000 training step(s), test accuracy using average model is 0.9837
</code></pre>
      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/深度学习/" rel="tag"># 深度学习</a>
          
            <a href="/tags/tensorflow/" rel="tag"># tensorflow</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/10/25/VS2017配置OpenCV3.2.0开发环境/" rel="next" title="Win7下配置VS2017+OpenCV3.2.0">
                <i class="fa fa-chevron-left"></i> Win7下配置VS2017+OpenCV3.2.0
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC8yOTc5Ny82MzYz"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="ailee" />
          <p class="site-author-name" itemprop="name">ailee</p>
           
              <p class="site-description motion-element" itemprop="description">优秀不够，一定要卓越，一定要无可替代才是最重要的。</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">16</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              友情链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://rootingc.me" title="rooting" target="_blank">rooting</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://mindthink.me/" title="mindthink" target="_blank">mindthink</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.yoogu.cc/" title="Wakke Wang" target="_blank">Wakke Wang</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://ictar.github.io" title="Ele A面" target="_blank">Ele A面</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-1-张量和图"><span class="nav-number">1.</span> <span class="nav-text">1.1 张量和图</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-2-占位符和feed-dict"><span class="nav-number">2.</span> <span class="nav-text">1.2 占位符和feed_dict</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#下面是使用占位符的案例："><span class="nav-number">2.1.</span> <span class="nav-text">下面是使用占位符的案例：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#解析一段构建了三层全连接神经网络的代码"><span class="nav-number">2.2.</span> <span class="nav-text">解析一段构建了三层全连接神经网络的代码</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#tensorflow中的神经网络"><span class="nav-number">3.</span> <span class="nav-text">tensorflow中的神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-简介"><span class="nav-number">3.1.</span> <span class="nav-text">2.1 简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-导入数据集"><span class="nav-number">3.2.</span> <span class="nav-text">2.2 导入数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-搭建一个简单的神经网络"><span class="nav-number">3.3.</span> <span class="nav-text">2.3 搭建一个简单的神经网络</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ailee</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      本站访客数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人次
    </span>
  

  
    <span class="site-pv">
      本站总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  






  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("3JEOnLBbeCkTnDLXdRB4RQNh-gzGzoHsz", "LpdXae1Pn9iCAuW8OVklkOqp");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  


  

  

</body>
</html>
